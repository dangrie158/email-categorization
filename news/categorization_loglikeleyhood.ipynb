{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorization using log-likelihood of word2vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-14T21:07:43.138223",
     "start_time": "2017-01-14T21:07:42.169189"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Library/Python/2.7/lib/python/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from pandas import DataFrame\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "construct the file names for the learned models and the validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-14T21:08:39.293753",
     "start_time": "2017-01-14T21:08:39.288035"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "category_names = ['Sonstiges', 'Aktuell', 'Lifestyle', \n",
    "          'Wirtschaft', 'Finanzen', 'Ausland', 'Lokal', \n",
    "          'Politik', 'Sport', 'Technologie', 'Kultur']\n",
    "\n",
    "num_models = len(category_names)\n",
    "model_paths = [\"data/corpus{}+base.200dim.word2vec.model\".format(x) for x in category_names]\n",
    "validation_paths = [\"data/corpus{}.validation.txt\".format(x) for x in category_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "load the validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-14T21:08:40.679582",
     "start_time": "2017-01-14T21:08:40.380279"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of articles used for validation:\n",
      "             dim(V_i)\n",
      "Sonstiges         770\n",
      "Aktuell            20\n",
      "Lifestyle         328\n",
      "Wirtschaft        817\n",
      "Finanzen          333\n",
      "Ausland           483\n",
      "Lokal             249\n",
      "Politik          1596\n",
      "Sport             449\n",
      "Technologie       361\n",
      "Kultur            217\n"
     ]
    }
   ],
   "source": [
    "validators = [LineSentence(path) for path in validation_paths]\n",
    "\n",
    "num_validation_entries = [sum([1 for _ in x]) for x in validators]\n",
    "validation_stats = DataFrame(num_validation_entries, category_names, ['dim(V_i)'])\n",
    "print('number of articles used for validation:')\n",
    "print(validation_stats) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Validation\n",
    "\n",
    "validate each validation set with all models and calculate the score (log likelihood) of each sentence for each model.\n",
    "\n",
    "scores is an array in the form:\n",
    "\n",
    "    [for each model:\n",
    "        [for each validation set:\n",
    "            [score of each sentence]\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "**Note**:\n",
    "There is no cross validation implemented, since it would require learning the category models ${ M }_{ i }$ on-the-fly which is in the current implementation too needy for memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-14T21:08:42.076142",
     "start_time": "2017-01-14T21:08:42.071758"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_scores(model_path):\n",
    "    # load the model\n",
    "    print('loading model {}'.format(model_path))\n",
    "    model =  Word2Vec.load(model_path)\n",
    "    # calculate the score (log likelihood) of each validation set for this model\n",
    "    print('validating model...')\n",
    "    scores = [model.score(validator) for validator in validators]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "main loop that calculates the scores for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-14T21:15:53.042180",
     "start_time": "2017-01-14T21:08:43.204822"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model data/corpusSonstiges+base.200dim.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusAktuell+base.200dim.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusLifestyle+base.200dim.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusWirtschaft+base.200dim.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusFinanzen+base.200dim.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusAusland+base.200dim.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusLokal+base.200dim.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusPolitik+base.200dim.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusSport+base.200dim.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusTechnologie+base.200dim.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusKultur+base.200dim.word2vec.model\n",
      "validating model...\n"
     ]
    }
   ],
   "source": [
    "#container to hold the calculated scores\n",
    "scores = []\n",
    "\n",
    "for model in model_paths:\n",
    "    model_scores = get_scores(model)\n",
    "    scores.append(model_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Log Likelihood\n",
    "\n",
    "output the average score (log likelihood) of all sentences in a validation set for one model\n",
    "\n",
    "row = average likelihood that an item of this category is generated by the model in the row\n",
    "\n",
    "e.g: the lowest value in each column is the category a sentence of this model is most likely classified to\n",
    "\n",
    "$$ { S }_{ i,j }=\\frac { \\sum _{ s=1 }^{ dim({ V }_{ i }) }{ score({ S(V }_{ i },\\quad s),\\quad { M }_{ j }) }  }{ dim({ V }_{ i }) } $$\n",
    "\n",
    "where:\n",
    "* ${ V }_{ i } $ is the validationset for category $i$\n",
    "* ${ M }_{ i } $ is the model trained for category $i$\n",
    "* ${ S }_{ i,j }$ is the score ($i$ is the column, $j$ is the row in the table)\n",
    "* $S({V}_{i}, x)$ is the $x$th sentence in the validation set ${V}_{i}$\n",
    "* $dim({ V }_{ i })$ is the number of elements in the validation set\n",
    "* $score(s, m)$ is the log-likelihood that the word is generated by the model [[Taddy, Matt. Document Classification by Inversion of Distributed Language Representations](https://arxiv.org/pdf/1504.07295.pdf)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-14T21:18:16.692361",
     "start_time": "2017-01-14T21:18:16.653856"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Sonstiges      Aktuell    Lifestyle   Wirtschaft     Finanzen  \\\n",
      "Sonstiges   -3010.084928 -3620.930076 -3316.684047 -3428.110842 -3470.883899   \n",
      "Aktuell     -3342.287811 -3502.018492 -3442.068571 -3354.793344 -3558.918169   \n",
      "Lifestyle   -3411.059577 -3741.202155 -3233.621596 -3353.026731 -3641.836474   \n",
      "Wirtschaft  -2220.297472 -2389.661734 -2083.490276 -1863.786035 -2240.937092   \n",
      "Finanzen    -2820.391919 -3376.509877 -3022.316987 -2871.141353 -2434.042256   \n",
      "Ausland     -2118.389157 -2299.874385 -2225.302254 -2162.516560 -2305.146807   \n",
      "Lokal       -4992.469881 -5883.736465 -5182.716055 -5553.870577 -5203.016032   \n",
      "Politik     -3222.012936 -3683.076455 -3300.886094 -3248.723149 -3440.617581   \n",
      "Sport       -4089.661399 -4552.034989 -4251.830995 -4440.834318 -4350.140081   \n",
      "Technologie -3643.723178 -3964.762998 -3671.437263 -3708.586836 -3770.256772   \n",
      "Kultur      -8901.370265 -9732.151271 -9192.834764 -9610.559394 -9710.615421   \n",
      "\n",
      "                 Ausland        Lokal  "
     ]
    }
   ],
   "source": [
    "average_scores = []\n",
    "for score_set in scores:\n",
    "    average_scores.append([sum(x) / len(x) for x in score_set])\n",
    "\n",
    "#transpose the array before creating the DataFrame because pandas is row-oriented\n",
    "result = DataFrame(np.transpose(average_scores), category_names, category_names)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification Quality\n",
    "calculate the number of categorizations for every category\n",
    "\n",
    "rows = categories of training set\n",
    "\n",
    "columns = number of items of the train set classified in the category\n",
    "\n",
    "e.g: the highest number in each row should be on the diagonal of the matrix\n",
    "\n",
    "first step is to transpose the model (switch the first two dimensions from model->category to category->model), then numpy.argmax is used to find the index of the model that has the highest score for this category\n",
    "\n",
    "$${ C }_{ i,j }=\\sum { \\begin{cases} 1\\quad if\\quad { S }_{ i,j }\\quad >\\quad \\underset { k\\in { V }\\setminus { V }_{ i } }{ max({ S }_{ k,j }) }  \\\\ 0\\quad otherwise \\end{cases} } $$\n",
    "\n",
    "where:\n",
    "* ${ C }_{ i,j }$ is the number of elements in ${V}_{i}$ that have are classified to ${M}_{i}$\n",
    "* ${ S }_{ i,j }\\quad >\\quad \\underset { k\\in { V }\\setminus { V }_{ i } }{ max({ S }_{ k,j }) } $ is the classification rule that assigns the article to the class that yields the highest score for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-14T21:18:20.471144",
     "start_time": "2017-01-14T21:18:20.436959"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Sonstiges  Aktuell  Lifestyle  Wirtschaft  Finanzen  Ausland  \\\n",
      "Sonstiges          507        0         85          28        10       31   \n",
      "Aktuell              8        1          1           6         0        1   \n",
      "Lifestyle           87        0        145          27         6       13   \n",
      "Wirtschaft          43        0         34         575        66       18   \n",
      "Finanzen            11        0          5          91       212        1   \n",
      "Ausland             39        1          8          29         3      184   \n",
      "Lokal               23        0          7          23         0        2   \n",
      "Politik            118        0         19          97         7      175   \n",
      "Sport               14        0          1           7         2        0   \n",
      "Technologie         25        0         22          27         3        5   \n",
      "Kultur              71        0         34           9         1        8   \n",
      "\n",
      "             Lokal  Politik  Sport  Technologie  Kultur  \n",
      "Sonstiges       1"
     ]
    }
   ],
   "source": [
    "classification_matrix = np.empty([num_models, num_models], dtype=int)\n",
    "\n",
    "for category_index in range(num_models):\n",
    "    #transpose the scores array to form [model][category][sentence_score] to [category][model][sentence_score]\n",
    "    category_scores = [model[category_index] for model in scores]\n",
    "    #get the classification matrix in each model\n",
    "    #the values represent the category index they were assigned to\n",
    "    classifications = np.argmax(category_scores, axis = 0)\n",
    "    \n",
    "    #convert the classification matrix to a count of classification in each category\n",
    "    classification_count = [np.sum(classifications == x) for x in range(len(category_names))]\n",
    "    classification_matrix[category_index]=classification_count\n",
    "    \n",
    "result = DataFrame(classification_matrix, category_names, category_names)\n",
    "print(result)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accuracy\n",
    "\n",
    "Calculate the accuracy matrix. Accuracy is defined as \n",
    "$\\frac { TP +TN }{ total\\ elements }$\n",
    "\n",
    "$${ ACC }_{ i,j }=\\frac { { C }_{ i,j } }{ \\sum { { C }_{ j } }  } $$\n",
    "\n",
    "**Note**:\n",
    "True accuracy measures as per definition are only found on the diagonal of the matrix. The other values are the ratio of false positives in the corresponding category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-14T21:18:24.982683",
     "start_time": "2017-01-14T21:18:24.953780"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Sonstiges  Aktuell  Lifestyle  Wirtschaft  Finanzen   Ausland  \\\n",
      "Sonstiges     0.658442  0.00000   0.110390    0.036364  0.012987  0.040260   \n",
      "Aktuell       0.400000  0.05000   0.050000    0.300000  0.000000  0.050000   \n",
      "Lifestyle     0.265244  0.00000   0.442073    0.082317  0.018293  0.039634   \n",
      "Wirtschaft    0.052632  0.00000   0.041616    0.703794  0.080783  0.022032   \n",
      "Finanzen      0.033033  0.00000   0.015015    0.273273  0.636637  0.003003   \n",
      "Ausland       0.080745  0.00207   0.016563    0.060041  0.006211  0.380952   \n",
      "Lokal         0.092369  0.00000   0.028112    0.092369  0.000000  0.008032   \n",
      "Politik       0.073935  0.00000   0.011905    0.060777  0.004386  0.109649   \n",
      "Sport         0.031180  0.00000   0.002227    0.015590  0.004454  0.000000   \n",
      "Technologie   0.069252  0.00000   0.060942    0.074792  0.008310  0.013850   \n",
      "Kultur        0.327189  0.00000   0.156682    0.041475  0.004608  0.036866   \n",
      "\n",
      "                Lokal   Politik     Sport  Technologie    Kultu"
     ]
    }
   ],
   "source": [
    "# the max(, 1) function surrounding sum makes sure wo don't divide by 0 if no match occurred\n",
    "accuracy_matrix = [category / float(max([sum(category) ,1])) for category in classification_matrix]\n",
    "\n",
    "result = DataFrame(accuracy_matrix, category_names, category_names)\n",
    "print(result) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "calculate the average accuracy of the diagonal to get a accuracy score\n",
    "\n",
    "$$score=\\frac { \\sum _{ i=0 }^{ dim({ V }_{ i }) }{ { ACC }_{ i,i } * dim({ V }_{ i }) }  }{  \\sum _{ i=0 }^{ dim({ V }_{ i }) }{dim({ V }_{ i }) }   } $$\n",
    "\n",
    "This value is comparable with the accuracy validation score of scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-14T21:18:30.389707",
     "start_time": "2017-01-14T21:18:30.383507"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.658723101547\n"
     ]
    }
   ],
   "source": [
    "true_positives = 0.0\n",
    "num_samples = 0\n",
    "for x in range(num_models):\n",
    "    true_positives += classification_matrix[x][x]\n",
    "    num_samples += sum(classification_matrix[x])\n",
    "    \n",
    "average_score = true_positives / num_samples\n",
    "\n",
    "print('score: {}'.format(average_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
