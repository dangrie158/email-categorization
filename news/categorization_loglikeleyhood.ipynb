{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorization using log-likelihood of word2vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-22T16:12:43.775361",
     "start_time": "2017-01-22T16:12:43.409827"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from pandas import DataFrame\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "construct the file names for the learned models and the validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-22T16:12:43.928752",
     "start_time": "2017-01-22T16:12:43.806627"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "category_names = ['Sonstiges', 'Lifestyle', \n",
    "          'Wirtschaft', 'Finanzen', 'Lokal', \n",
    "          'Politik', 'Sport', 'Technologie', 'Kultur']\n",
    "\n",
    "num_models = len(category_names)\n",
    "model_paths = [\"data/corpus{}+base.word2vec.model\".format(x) for x in category_names]\n",
    "validation_paths = [\"data/corpus{}.validation.txt\".format(x) for x in category_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "load the validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-22T16:12:45.059046",
     "start_time": "2017-01-22T16:12:43.934434"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of articles used for validation:\n",
      "             dim(V_i)\n",
      "Sonstiges         770\n",
      "Lifestyle         328\n",
      "Wirtschaft        817\n",
      "Finanzen          333\n",
      "Lokal             249\n",
      "Politik          1596\n",
      "Sport             449\n",
      "Technologie       361\n",
      "Kultur            217\n"
     ]
    }
   ],
   "source": [
    "num_validation_entries = [sum([1 for _ in x]) for x in validators]\n",
    "validation_stats = DataFrame(num_validation_entries, category_names, ['dim(V_i)'])\n",
    "print('number of articles used for validation:')\n",
    "print(validation_stats) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Validation\n",
    "\n",
    "validate each validation set with all models and calculate the score (log likelihood) of each sentence for each model.\n",
    "\n",
    "scores is an array in the form:\n",
    "\n",
    "    [for each model:\n",
    "        [for each validation set:\n",
    "            [score of each sentence]\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "**Note**:\n",
    "There is no cross validation implemented, since it would require learning the category models ${ M }_{ i }$ on-the-fly which is in the current implementation too needy for memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-22T16:12:45.133172",
     "start_time": "2017-01-22T16:12:45.075223"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_scores(model_path):\n",
    "    # load the model\n",
    "    print('loading model {}'.format(model_path))\n",
    "    model =  Word2Vec.load(model_path)\n",
    "    # calculate the score (log likelihood) of each validation set for this model\n",
    "    print('validating model...')\n",
    "    scores = [model.score(validator) for validator in validators]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "main loop that calculates the scores for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-22T16:27:54.129396",
     "start_time": "2017-01-22T16:12:45.153024"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model data/corpusSonstiges+base.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusLifestyle+base.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusWirtschaft+base.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusFinanzen+base.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusLokal+base.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusPolitik+base.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusSport+base.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusTechnologie+base.word2vec.model\n",
      "validating model...\n",
      "loading model data/corpusKultur+base.word2vec.model\n",
      "validating model...\n"
     ]
    }
   ],
   "source": [
    "#container to hold the calculated scores\n",
    "scores = []\n",
    "\n",
    "for model in model_paths:\n",
    "    model_scores = get_scores(model)\n",
    "    scores.append(model_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Log Likelihood\n",
    "\n",
    "output the average score (log likelihood) of all sentences in a validation set for one model\n",
    "\n",
    "row = average likelihood that an item of this category is generated by the model in the row\n",
    "\n",
    "e.g: the lowest value in each column is the category a sentence of this model is most likely classified to\n",
    "\n",
    "$$ { S }_{ i,j }=\\frac { \\sum _{ s=1 }^{ dim({ V }_{ i }) }{ score({ S(V }_{ i },\\quad s),\\quad { M }_{ j }) }  }{ dim({ V }_{ i }) } $$\n",
    "\n",
    "where:\n",
    "* ${ V }_{ i } $ is the validationset for category $i$\n",
    "* ${ M }_{ i } $ is the model trained for category $i$\n",
    "* ${ S }_{ i,j }$ is the score ($i$ is the column, $j$ is the row in the table)\n",
    "* $S({V}_{i}, x)$ is the $x$th sentence in the validation set ${V}_{i}$\n",
    "* $dim({ V }_{ i })$ is the number of elements in the validation set\n",
    "* $score(s, m)$ is the log-likelihood that the word is generated by the model [[Taddy, Matt. Document Classification by Inversion of Distributed Language Representations](https://arxiv.org/pdf/1504.07295.pdf)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-22T16:27:54.277031",
     "start_time": "2017-01-22T16:27:54.143403"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Sonstiges    Lifestyle   Wirtschaft     Finanzen        Lokal  \\\n",
      "Sonstiges   -3023.305563 -3316.458243 -3458.459421 -3502.693819 -3505.015840   \n",
      "Lifestyle   -3470.167490 -3230.019704 -3379.121821 -3694.238708 -3715.646034   \n",
      "Wirtschaft  -2255.291836 -2080.033885 -1850.201417 -2273.048428 -2399.692025   \n",
      "Finanzen    -2819.153567 -3010.546884 -2862.410102 -2414.655164 -3275.942700   \n",
      "Lokal       -5072.434925 -5172.428481 -5601.607124 -5249.026092 -3597.520388   \n",
      "Politik     -3259.656002 -3270.765876 -3251.658240 -3473.375445 -3537.727668   \n",
      "Sport       -4126.546658 -4262.982045 -4460.560663 -4381.310551 -4225.625471   \n",
      "Technologie -3697.492521 -3691.743123 -3755.177561 -3831.746594 -3912.820028   \n",
      "Kultur      -9062.581682 -9165.819357 -9754.343478 -9762.327799 -9793.236392   \n",
      "\n",
      "                 Politik        Sport  Technologie       Kultur  \n",
      "Sonstiges   -3379.924037 -3522.187860 -3398.669042 -3492.243594  \n",
      "Lifestyle   -3449.871508 -3675.448228 -3533.370444 -3649.240762  \n",
      "Wirtschaft  -2053.638446 -2410.441619 -2282.837630 -2402.273746  \n",
      "Finanzen    -2810.082474 -3084.442941 -2969.477116 -3177.670412  \n",
      "Lokal       -5268.041963 -5126.760869 -5165.527470 -5354.149361  \n",
      "Politik     -2677.870403 -3575.539200 -3463.818701 -3572.767868  \n",
      "Sport       -4358.160572 -3246.637112 -4242.314711 -4374.986282  \n",
      "Technologie -3881.311316 -3912.132513 -3425.718507 -3884.793006  \n",
      "Kultur      -9502.000836 -9660.519725 -9371.441661 -6192.573605  \n"
     ]
    }
   ],
   "source": [
    "average_scores = []\n",
    "for score_set in scores:\n",
    "    average_scores.append([sum(x) / len(x) for x in score_set])\n",
    "\n",
    "#transpose the array before creating the DataFrame because pandas is row-oriented\n",
    "result = DataFrame(np.transpose(average_scores), category_names, category_names)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification Quality\n",
    "calculate the number of categorizations for every category\n",
    "\n",
    "rows = categories of training set\n",
    "\n",
    "columns = number of items of the train set classified in the category\n",
    "\n",
    "e.g: the highest number in each row should be on the diagonal of the matrix\n",
    "\n",
    "first step is to transpose the model (switch the first two dimensions from model->category to category->model), then numpy.argmax is used to find the index of the model that has the highest score for this category\n",
    "\n",
    "$${ C }_{ i,j }=\\sum { \\begin{cases} 1\\quad if\\quad { S }_{ i,j }\\quad >\\quad \\underset { k\\in { V }\\setminus { V }_{ i } }{ max({ S }_{ k,j }) }  \\\\ 0\\quad otherwise \\end{cases} } $$\n",
    "\n",
    "where:\n",
    "* ${ C }_{ i,j }$ is the number of elements in ${V}_{i}$ that have are classified to ${M}_{i}$\n",
    "* ${ S }_{ i,j }\\quad >\\quad \\underset { k\\in { V }\\setminus { V }_{ i } }{ max({ S }_{ k,j }) } $ is the classification rule that assigns the article to the class that yields the highest score for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-22T16:27:54.330291",
     "start_time": "2017-01-22T16:27:54.280513"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Sonstiges  Lifestyle  Wirtschaft  Finanzen  Lokal  Politik  \\\n",
      "Sonstiges          452        154          40        10     10       58   \n",
      "Lifestyle           52        182          29         6      0       29   \n",
      "Wirtschaft          29         52         593        67      2       30   \n",
      "Finanzen            10          9          98       208      0        3   \n",
      "Lokal               21         12          21         1    158       30   \n",
      "Politik            115         46         121        13      7     1280   \n",
      "Sport               13          3          10         2      1        0   \n",
      "Technologie         14         33          29         3      0       10   \n",
      "Kultur              46         62           8         2      2        2   \n",
      "\n",
      "             Sport  Technologie  Kultur  \n",
      "Sonstiges        5           19      22  \n",
      "Lifestyle        4           16      10  \n",
      "Wirtschaft       1           41       2  \n",
      "Finanzen         0            5       0  \n",
      "Lokal            0            5       1  \n",
      "Politik          0           12       2  \n",
      "Sport          418            2       0  \n",
      "Technologie      0          265       7  \n",
      "Kultur           2           18      75  \n"
     ]
    }
   ],
   "source": [
    "classification_matrix = np.empty([num_models, num_models], dtype=int)\n",
    "\n",
    "for category_index in range(num_models):\n",
    "    #transpose the scores array to form [model][category][sentence_score] to [category][model][sentence_score]\n",
    "    category_scores = [model[category_index] for model in scores]\n",
    "    #get the classification matrix in each model\n",
    "    #the values represent the category index they were assigned to\n",
    "    classifications = np.argmax(category_scores, axis = 0)\n",
    "    \n",
    "    #convert the classification matrix to a count of classification in each category\n",
    "    classification_count = [np.sum(classifications == x) for x in range(len(category_names))]\n",
    "    classification_matrix[category_index]=classification_count\n",
    "    \n",
    "result = DataFrame(classification_matrix, category_names, category_names)\n",
    "print(result)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accuracy\n",
    "\n",
    "Calculate the accuracy matrix. Accuracy is defined as \n",
    "$\\frac { TP +TN }{ total\\ elements }$\n",
    "\n",
    "$${ ACC }_{ i,j }=\\frac { { C }_{ i,j } }{ \\sum { { C }_{ j } }  } $$\n",
    "\n",
    "**Note**:\n",
    "True accuracy measures as per definition are only found on the diagonal of the matrix. The other values are the ratio of false positives in the corresponding category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-22T16:27:54.366194",
     "start_time": "2017-01-22T16:27:54.333371"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Sonstiges  Lifestyle  Wirtschaft  Finanzen     Lokal   Politik  \\\n",
      "Sonstiges     0.587013   0.200000    0.051948  0.012987  0.012987  0.075325   \n",
      "Lifestyle     0.158537   0.554878    0.088415  0.018293  0.000000  0.088415   \n",
      "Wirtschaft    0.035496   0.063647    0.725826  0.082007  0.002448  0.036720   \n",
      "Finanzen      0.030030   0.027027    0.294294  0.624625  0.000000  0.009009   \n",
      "Lokal         0.084337   0.048193    0.084337  0.004016  0.634538  0.120482   \n",
      "Politik       0.072055   0.028822    0.075815  0.008145  0.004386  0.802005   \n",
      "Sport         0.028953   0.006682    0.022272  0.004454  0.002227  0.000000   \n",
      "Technologie   0.038781   0.091413    0.080332  0.008310  0.000000  0.027701   \n",
      "Kultur        0.211982   0.285714    0.036866  0.009217  0.009217  0.009217   \n",
      "\n",
      "                Sport  Technologie    Kultur  \n",
      "Sonstiges    0.006494     0.024675  0.028571  \n",
      "Lifestyle    0.012195     0.048780  0.030488  \n",
      "Wirtschaft   0.001224     0.050184  0.002448  \n",
      "Finanzen     0.000000     0.015015  0.000000  \n",
      "Lokal        0.000000     0.020080  0.004016  \n",
      "Politik      0.000000     0.007519  0.001253  \n",
      "Sport        0.930958     0.004454  0.000000  \n",
      "Technologie  0.000000     0.734072  0.019391  \n",
      "Kultur       0.009217     0.082949  0.345622  \n"
     ]
    }
   ],
   "source": [
    "# the max(, 1) function surrounding sum makes sure wo don't divide by 0 if no match occurred\n",
    "accuracy_matrix = [category / float(max([sum(category) ,1])) for category in classification_matrix]\n",
    "\n",
    "result = DataFrame(accuracy_matrix, category_names, category_names)\n",
    "print(result) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "calculate the average accuracy of the diagonal to get a accuracy score\n",
    "\n",
    "$$score=\\frac { \\sum _{ i=0 }^{ dim({ V }_{ i }) }{ { ACC }_{ i,i } * dim({ V }_{ i }) }  }{  \\sum _{ i=0 }^{ dim({ V }_{ i }) }{dim({ V }_{ i }) }   } $$\n",
    "\n",
    "This value is comparable with the accuracy validation score of scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-22T16:27:54.378128",
     "start_time": "2017-01-22T16:27:54.368765"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.7091796875\n"
     ]
    }
   ],
   "source": [
    "true_positives = 0.0\n",
    "num_samples = 0\n",
    "for x in range(num_models):\n",
    "    true_positives += classification_matrix[x][x]\n",
    "    num_samples += sum(classification_matrix[x])\n",
    "    \n",
    "average_score = true_positives / num_samples\n",
    "\n",
    "print('score: {}'.format(average_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
